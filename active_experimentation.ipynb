{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.random as rng\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iso.csv')\n",
    "df = df[df['r1_charge_heater'] >= 0]\n",
    "\n",
    "min_yield_perc = 99\n",
    "min_ron = 83\n",
    "\n",
    "valid_comb_ix = (df['process_ron'] >= min_ron) & (df['process_yield'] >= min_yield_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_trace(df, chosen_ixs, min_ron, min_yield):\n",
    "    \n",
    "    traced_ch = df.iloc[chosen_ixs]['r1_charge_heater']\n",
    "    traced_ron = df.iloc[chosen_ixs]['process_ron']\n",
    "    traced_yield = df.iloc[chosen_ixs]['process_yield']\n",
    "    \n",
    "    feasibles_ix = (traced_ron >= min_ron) & (traced_yield >= min_yield)\n",
    "    \n",
    "    adjusted_ch = traced_ch * feasibles_ix + (1-feasibles_ix) * -1\n",
    "    adjusted_ch[adjusted_ch==-1]=np.inf\n",
    "    \n",
    "    best_ch = nanmin_accumulate(adjusted_ch)\n",
    "    return best_ch, feasibles_ix\n",
    "\n",
    "def nanmin_accumulate(vals):\n",
    "    acc = []\n",
    "    min_val = float(\"inf\")\n",
    "    for val in vals:\n",
    "        if val < min_val:\n",
    "            min_val = val\n",
    "        acc.append(min_val)\n",
    "    return acc \n",
    "N_EXPS = 500\n",
    "N_REPS = 100\n",
    "\n",
    "traces = []\n",
    "f_traces = []\n",
    "for r in range(N_REPS):\n",
    "    random_ix = rng.permutation(df.shape[0])[:N_EXPS]\n",
    "    best_ch, feasibles_ix = build_trace(df, random_ix, min_ron, min_yield_perc)\n",
    "    traces.append(best_ch)\n",
    "    f_traces.append(feasibles_ix)\n",
    "\n",
    "avg_best_random = np.mean(traces, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "ax.plot(np.arange(avg_best_random.shape[0]), avg_best_random, linewidth=5, label='Random')\n",
    "ax.plot(np.arange(avg_best_random.shape[0]), np.ones(avg_best_random.shape[0]) * \n",
    "        np.min(df[valid_comb_ix]['r1_charge_heater']), linewidth=5, linestyle='--', label='True Min')\n",
    "ax.tick_params(axis='x', labelsize=22)\n",
    "ax.tick_params(axis='y', labelsize=22)\n",
    "ax.set_xlabel('# Experiments', fontsize=28, fontweight='bold')\n",
    "ax.set_ylabel('Best Feasible Charge Heater', fontsize=28, fontweight='bold')\n",
    "ax.grid(True)\n",
    "ax.legend(fontsize=28, frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from warnings import catch_warnings\n",
    "from warnings import simplefilter\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[['r1_temp', 'r2_temp', 'r1_pressure', 'r2_pressure']])\n",
    "y = np.array(df[['r1_charge_heater']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surrogate or approximation for the objective function\n",
    "def surrogate(model, X):\n",
    "\t# catch any warning generated when making a prediction\n",
    "\twith catch_warnings():\n",
    "\t\t# ignore generated warnings\n",
    "\t\tsimplefilter(\"ignore\")\n",
    "\t\treturn model.predict(X, return_std=True)\n",
    "\n",
    "# probability of improvement acquisition function\n",
    "def acquisition(X, Xsamples, avail_indecies, model):\n",
    "    \n",
    "\t# calculate the best surrogate score found so far\n",
    "    yhat, _ = surrogate(model, X)\n",
    "    best = min(yhat)\n",
    "    \n",
    "    #print(best)\n",
    "\t# calculate mean and stdev via surrogate function\n",
    "    mu, std = surrogate(model, Xsamples)\n",
    "\n",
    "    mu = mu[:, 0]\n",
    "\t# calculate the probability of improvement\n",
    "    probs = norm.cdf((best - mu) / (std+1E-9))\n",
    "    \n",
    "    # don't pick anything that has already been used\n",
    "    \n",
    "    probs[~avail_indecies] = 0\n",
    "    \n",
    "    return probs\n",
    "\n",
    "# optimize the acquisition function\n",
    "def opt_acquisition(Xsamples, avail_indecies, X, y, model):\n",
    "\t\n",
    "\t# calculate the acquisition function for each sample\n",
    "    scores = acquisition(X, Xsamples, avail_indecies, model)\n",
    "    \n",
    "    # locate the index of the largest scores\n",
    "    ix = rng.permutation(scores.shape[0])\n",
    "    best_ix = max(ix, key=lambda i: scores[i])\n",
    "    \n",
    "    return best_ix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES_TO_DRAW = 50\n",
    "REPS = 100\n",
    "\n",
    "best_chs = []\n",
    "indecies = set(range(X.shape[0]))\n",
    "\n",
    "for r in range(REPS):\n",
    "    # initialize the model\n",
    "    ix = rng.choice(X.shape[0], 1)\n",
    "    Xtrain = X[ix,:]\n",
    "    ytrain = y[ix,:] * valid_comb_ix[ix] + (1-valid_comb_ix[ix]) * 1e9\n",
    "    \n",
    "    model = GaussianProcessRegressor()\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    \n",
    "    best_ch = [ytrain[0,0]]\n",
    "    # perform the optimization process\n",
    "    avail_indecies = np.ones(X.shape[0]).astype(bool)\n",
    "    avail_indecies[ix] = False \n",
    "   \n",
    "    for i in range(N_SAMPLES_TO_DRAW-1):\n",
    "\n",
    "        # select the next point to sample\n",
    "        #ix = rng.permutation(X.shape[0])[:N_SAMPLES_TO_DRAW]\n",
    "        #Xsamples = X[ix,:]\n",
    "        ix = opt_acquisition(X, avail_indecies, Xtrain, ytrain, model)\n",
    "        avail_indecies[ix] = False\n",
    "        \n",
    "        # sample the point\n",
    "        actual = y[ix,:] * valid_comb_ix[ix] + (1-valid_comb_ix[ix]) * 1e9\n",
    "        \n",
    "        # add the data to the dataset\n",
    "        Xtrain = np.vstack((Xtrain, X[ix,:]))\n",
    "        ytrain = np.vstack((ytrain, actual))\n",
    "        best_ch.append(np.min(ytrain))\n",
    "        \n",
    "        \n",
    "        # update the model\n",
    "        model.fit(Xtrain, ytrain)\n",
    "    best_chs.append(best_ch)\n",
    "best_chs = np.array(best_chs)\n",
    "\n",
    "avg_best_bo = np.mean(best_chs, axis=0)\n",
    "avg_best_bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "ax.plot(np.arange(avg_best_bo.shape[0]), avg_best_bo, linewidth=5, label='BayesOpt')\n",
    "ax.plot(np.arange(avg_best_random.shape[0]), avg_best_random, linewidth=5, label='Random')\n",
    "ax.plot(np.arange(avg_best_random.shape[0]), np.ones_like(r1_charge_heater) * np.min(r1_charge_heater[valid_comb_ix]), linewidth=5, linestyle='--', label='True Min')\n",
    "ax.tick_params(axis='x', labelsize=22)\n",
    "ax.tick_params(axis='y', labelsize=22)\n",
    "ax.set_xlabel('# Experiments', fontsize=28, fontweight='bold')\n",
    "ax.set_ylabel('Best Charge Heater', fontsize=28, fontweight='bold')\n",
    "ax.set_xlim([0, N_SAMPLES_TO_DRAW])\n",
    "ax.grid(True)\n",
    "ax.set_yscale('log')\n",
    "ax.legend(fontsize=28, frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(r1_charge_heater[valid_comb_ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SurrogateModel:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._X = []\n",
    "        self._y = []\n",
    "        \n",
    "    def add_observation(self, x, y):\n",
    "        self._X.append(x)\n",
    "        self._y.append(y)\n",
    "        \n",
    "        Xtrain, ytrain = self.get_train_data()\n",
    "#         print(\"Xtrain shape: \", Xtrain.shape)\n",
    "#         print(\"ytrain shape: \", ytrain.shape)\n",
    "        self._model = GaussianProcessRegressor()\n",
    "    \n",
    "        self._model.fit(Xtrain, ytrain)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # catch any warning generated when making a prediction\n",
    "        with catch_warnings():\n",
    "            # ignore generated warnings\n",
    "            simplefilter(\"ignore\")\n",
    "            return self._model.predict(X, return_std=True)\n",
    "    \n",
    "    def prob_less_than(self, X, thres):\n",
    "        mu, std = self.predict(X)\n",
    "\n",
    "        mu = mu[:,0]\n",
    "        \n",
    "        probs = norm.cdf((thres - mu) / (std+1E-9))\n",
    "        \n",
    "        return probs \n",
    "    \n",
    "    def prob_greater_than(self, X, thres):\n",
    "        mu, std = self.predict(X)\n",
    "\n",
    "        mu = mu[:,0]\n",
    "        \n",
    "        probs = norm.cdf((mu - thres) / (std+1E-9))\n",
    "        \n",
    "        return probs \n",
    "    \n",
    "    def get_train_data(self):\n",
    "        return np.array(self._X), np.array(self._y)\n",
    "\n",
    "def plot_trace(mean_trace, col_names):\n",
    "    f, axes = plt.subplots(3, 1, figsize=(10, 10), sharex=True)\n",
    "\n",
    "    for c in range(len(col_names)):\n",
    "        ax = axes[c]\n",
    "        \n",
    "        axes[c].plot(np.arange(mean_trace.shape[0]), mean_trace[:,c], linewidth=5, label=col_names[c])\n",
    "    \n",
    "        ax.tick_params(axis='x', labelsize=22)\n",
    "        ax.tick_params(axis='y', labelsize=22)\n",
    "        ax.set_xlabel('# Experiments', fontsize=28, fontweight='bold')\n",
    "        ax.set_ylabel('Best', fontsize=28, fontweight='bold')\n",
    "        ax.set_xlim([0, N_SAMPLES_TO_DRAW])\n",
    "        ax.grid(True)\n",
    "        ax.set_yscale('log')\n",
    "        ax.legend(fontsize=28, frameon=False)\n",
    "\n",
    "X = np.array(df[['r1_temp', 'r2_temp', 'r1_pressure', 'r2_pressure']])\n",
    "ys_ch = np.array(df[['r1_charge_heater']])\n",
    "ys_ron = np.array(df[['process_ron']])\n",
    "ys_yield = np.array(df[['process_yield']])\n",
    "min_ron = 83\n",
    "min_yield = 99\n",
    "\n",
    "N_SAMPLES_TO_DRAW = 50\n",
    "REPS = 10\n",
    "\n",
    "traces = []\n",
    "f_traces = []\n",
    "for r in range(REPS):\n",
    "    \n",
    "    # pick a random point to seed the model\n",
    "    ix = rng.choice(X.shape[0])\n",
    "    x = np.squeeze(X[ix,:])\n",
    "    y_ch = ys_ch[ix]\n",
    "    y_ron = ys_ron[ix]\n",
    "    y_yield = ys_yield[ix]\n",
    "    \n",
    "    # instantiate three sms\n",
    "    ch_sm = SurrogateModel()\n",
    "    ch_sm.add_observation(x, y_ch)\n",
    "    ron_sm = SurrogateModel()\n",
    "    ron_sm.add_observation(x, y_ron)\n",
    "    yield_sm = SurrogateModel()\n",
    "    yield_sm.add_observation(x, y_yield)\n",
    "    \n",
    "    # keep track of available experiments to run\n",
    "    avail_indecies = np.ones(X.shape[0]).astype(bool)\n",
    "    avail_indecies[ix] = False \n",
    "    \n",
    "    # track choices\n",
    "    chosen_ixs = [ix]\n",
    "    \n",
    "    for i in range(N_SAMPLES_TO_DRAW-1):\n",
    "        \n",
    "        \n",
    "        # calculate the probability of improving on the best charge heater value\n",
    "        Xtrain, ytrain_ch = ch_sm.get_train_data()\n",
    "        yhat_ch, _ = ch_sm.predict(Xtrain)\n",
    "        best_ch = min(yhat)\n",
    "         \n",
    "        pi = ch_sm.prob_less_than(X, best_ch)\n",
    "        \n",
    "        # calculate the probability that the ron will be higher than given threshold\n",
    "        p_ron_feasible = ron_sm.prob_greater_than(X, min_ron)\n",
    "        \n",
    "        # calculate the probability that the yield will be higher than given threshold\n",
    "        p_yield_feasible = yield_sm.prob_greater_than(X, min_yield)\n",
    "        \n",
    "        # now maximize the product of three probs\n",
    "        prob_goodness = p_ron_feasible * p_yield_feasible\n",
    "        #print(np.max(prob_goodness))\n",
    "        \n",
    "        prob_goodness[~avail_indecies] = 0\n",
    "        ix = rng.permutation(prob_goodness.shape[0])\n",
    "        next_ix = max(ix, key=lambda i: prob_goodness[i])\n",
    "        \n",
    "        # add results\n",
    "        x = np.squeeze(X[next_ix,:])\n",
    "        y_ch = ys_ch[next_ix]\n",
    "        y_ron = ys_ron[next_ix]\n",
    "        y_yield = ys_yield[next_ix]\n",
    "        ch_sm.add_observation(x, y_ch)\n",
    "        ron_sm.add_observation(x, y_ron)\n",
    "        yield_sm.add_observation(x, y_yield)\n",
    "    \n",
    "        # trace it\n",
    "        avail_indecies[next_ix] = False\n",
    "        chosen_ixs.append(next_ix)\n",
    "     \n",
    "    best_ch, feasibles_ix = build_trace(df, chosen_ixs, min_ron, min_yield_perc)\n",
    "    traces.append(best_ch)\n",
    "    f_traces.append(feasibles_ix)\n",
    "    \n",
    "avg_best_bo = np.mean(f_traces, axis=0)\n",
    "avg_best_bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "\n",
    "ax.plot(np.arange(avg_best_random.shape[0]), avg_best_random, linewidth=5, label='Random')\n",
    "ax.plot(np.arange(avg_best_bo.shape[0]), avg_best_bo, linewidth=5, label='Bayesopt')\n",
    "ax.plot(np.arange(avg_best_random.shape[0]), np.ones(avg_best_random.shape[0]) * \n",
    "        np.min(df[valid_comb_ix]['r1_charge_heater']), linewidth=5, linestyle='--', label='True Min')\n",
    "ax.tick_params(axis='x', labelsize=22)\n",
    "ax.tick_params(axis='y', labelsize=22)\n",
    "ax.set_xlabel('# Experiments', fontsize=28, fontweight='bold')\n",
    "ax.set_ylabel('Best Feasible Charge Heater', fontsize=28, fontweight='bold')\n",
    "ax.grid(True)\n",
    "ax.legend(fontsize=28, frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import scipy.stats as stats\n",
    "my_devices = tf.config.experimental.list_physical_devices(device_type='CPU')\n",
    "tf.config.experimental.set_visible_devices(devices= my_devices, device_type='CPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class StochasticNN:\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        self._cfg = cfg \n",
    "        \n",
    "        \n",
    "    def train(self, Xtrain, Ytrain):\n",
    "        \n",
    "        self._make_model()\n",
    "        \n",
    "        # normalize X and y train\n",
    "        Xtrain = stats.zscore(Xtrain, axis=0, ddof=1)\n",
    "        Ytrain_mu = np.mean(Ytrain, axis=0, keepdims=True)\n",
    "        Ytrain_std = np.std(Ytrain, axis=0, ddof=1, keepdims=True)\n",
    "        Ytrain = (Ytrain - Ytrain_mu) / Ytrain_std\n",
    "        \n",
    "        self._Ytrain_mu = Ytrain_mu\n",
    "        self._Ytrain_std = Ytrain_std\n",
    "        \n",
    "        history = self._model.fit(Xtrain, \n",
    "                                  Ytrain, \n",
    "                                  batch_size=Xtrain.shape[0]//10, \n",
    "                                  epochs=self._cfg['n_epochs'], \n",
    "                                  verbose=self._cfg['verbose'])\n",
    "        \n",
    "    def _make_model(self):\n",
    "        cfg = self._cfg \n",
    "        \n",
    "        keras.backend.clear_session()\n",
    "    \n",
    "        input_layer = keras.layers.Input(shape=(cfg['n_input'],))\n",
    "        hidden_layer = keras.layers.Dense(cfg['n_hidden'], activation='tanh')(input_layer)\n",
    "        dropout1_layer = keras.layers.Dropout(0.5)(hidden_layer, training=True)\n",
    "        output_layer = keras.layers.Dense(cfg['n_output'], activation='linear')(dropout1_layer)\n",
    "        \n",
    "        model = keras.Model(input_layer, output_layer)\n",
    "        model.compile(\n",
    "            loss=keras.losses.MeanAbsoluteError(),\n",
    "            optimizer=keras.optimizers.Nadam()\n",
    "        )\n",
    "        #print(model.summary())\n",
    "        self._model = model \n",
    "    \n",
    "    def predict(self, X, n_samples=2):\n",
    "        \n",
    "        X = stats.zscore(X, axis=0, ddof=1)\n",
    "        \n",
    "        samples = []\n",
    "        for i in range(n_samples):\n",
    "            preds = self._model.predict(X) * self._Ytrain_std + self._Ytrain_mu \n",
    "            samples.append(preds)\n",
    "        \n",
    "        samples = np.array(samples)\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest obs: [4.50380974e+06 8.35797172e+01 9.79699929e+01]\n",
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-06 11:52:39.781814: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-08-06 11:52:39.781984: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2021-08-06 11:52:39.839934: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-06 11:52:39.840127: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-08-06 11:52:39.968294: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-08-06 11:52:42.676014: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest obs: [3.07846301e+06 8.02640979e+01 1.00258603e+02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-06 11:52:48.249573: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2021-08-06 11:52:51.227793: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wg/ww9997m54zqctlgjr57c281r0000gn/T/ipykernel_66038/3973051681.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# sample predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mpred_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_PRED_SAMPLES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# compute the probability of feasibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/wg/ww9997m54zqctlgjr57c281r0000gn/T/ipykernel_66038/889056632.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, n_samples)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Ytrain_std\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Ytrain_mu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/sci/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1725\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/sci/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/sci/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/sci/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/sci/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/sci/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/sci/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "X = np.array(df[['r1_temp', 'r2_temp', 'r1_pressure', 'r2_pressure']])\n",
    "Y = np.array(df[['r1_charge_heater', 'process_ron', 'process_yield']])\n",
    "\n",
    "min_ron = 83\n",
    "min_yield = 99\n",
    "\n",
    "N_INIT_SAMPLES = 10\n",
    "N_SAMPLES_TO_DRAW = 50\n",
    "N_PRED_SAMPLES=20\n",
    "REPS = 10\n",
    "\n",
    "nn = StochasticNN({ \"n_input\" : 4, \"n_output\" : 3, \"n_hidden\" : 5, \"n_epochs\" : 50, \"verbose\" : False })\n",
    "\n",
    "bo_traces = []\n",
    "for r in range(REPS):\n",
    "    \n",
    "    # pick random points to seed the model\n",
    "    chosen_ix = rng.choice(X.shape[0], N_INIT_SAMPLES, replace=False).tolist()\n",
    "    \n",
    "    # keep track of available experiments to run\n",
    "    avail_indecies = np.ones(X.shape[0]).astype(bool)\n",
    "    avail_indecies[chosen_ix] = False \n",
    "    \n",
    "    while len(chosen_ix) < N_SAMPLES_TO_DRAW:\n",
    "        #print(\"%r %d \" % (r, len(chosen_ix)))\n",
    "        # train model\n",
    "        Xtrain = X[chosen_ix, :]\n",
    "        Ytrain = Y[chosen_ix, :]\n",
    "        print(\"Latest obs: %s\" % Ytrain[-1,:])\n",
    "        nn.train(Xtrain, Ytrain)\n",
    "        \n",
    "        # sample predictions\n",
    "        pred_samples = nn.predict(X, n_samples=N_PRED_SAMPLES)\n",
    "        \n",
    "        # compute the probability of feasibility\n",
    "        prob_goodness = np.mean((pred_samples[:,:,1] >= min_ron) & (pred_samples[:,:,2] >= min_yield), axis=0)\n",
    "        prob_goodness[chosen_ix] = 0\n",
    "        #print(\"Max prob goddness: %0.2f\" % np.max(prob_goodness))\n",
    "        # choose next point\n",
    "        ix = rng.permutation(prob_goodness.shape[0])\n",
    "        next_ix = max(ix, key=lambda i: prob_goodness[i])\n",
    "        chosen_ix.append(next_ix)\n",
    "    \n",
    "    bo_traces.append(chosen_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_ch_traces = []\n",
    "bo_f_traces = []\n",
    "for chosen_ix in bo_traces:\n",
    "    print(chosen_ix)\n",
    "    best_ch, feasibles_ix = build_trace(df, chosen_ix, min_ron, min_yield)\n",
    "    bo_ch_traces.append(best_ch)\n",
    "    bo_f_traces.append(feasibles_ix)\n",
    "\n",
    "avg_best_bo = np.mean(bo_ch_traces, axis=0)\n",
    "np.mean(bo_f_traces, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
